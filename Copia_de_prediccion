{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFYHmYWj8aQAJh+GQxALo8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MajoponceAcosta/ponac/blob/main/Copia_de_prediccion\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-9Ma7-UZFmC"
      },
      "outputs": [],
      "source": [
        "# src/config.py\n",
        "import os\n",
        "\n",
        "# Dataset\n",
        "DATA_URL = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/german.csv\"\n",
        "FEATURE_NAMES = [\n",
        "    \"Status\", \"Duration\", \"Credit_history\", \"Purpose\", \"Amount\", \"Savings\",\n",
        "    \"Employment\", \"Installment_rate\", \"Personal_status\", \"Debtors\",\n",
        "    \"Residence_time\", \"Property\", \"Age\", \"Other_installment\", \"Housing\",\n",
        "    \"Existing_credits\", \"Job\", \"Liable_people\", \"Telephone\", \"Foreign_worker\"\n",
        "]\n",
        "TARGET_NAME = \"Credit_risk\"  # 1 = Good, 2 = Bad ‚Üí convertiremos a 0/1\n",
        "\n",
        "# Model\n",
        "INPUT_DIM = 20\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# API\n",
        "API_URL = \"https://api.exchangerate.host/latest\"\n",
        "BASE_CURRENCY = \"USD\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# src/data/api_client.py\n",
        "import requests\n",
        "from typing import Optional\n",
        "\n",
        "def fetch_exchange_rate(base: str = \"USD\", target: str = \"EUR\") -> Optional[float]:\n",
        "    \"\"\"\n",
        "    Obtiene la tasa de cambio desde una API p√∫blica.\n",
        "    Por defecto: USD -> EUR (√∫til si los datos est√°n en EUR y queremos USD).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        url = f\"https://api.exchangerate.host/latest?base={base}&symbols={target}\"\n",
        "        response = requests.get(url, timeout=5)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data[\"rates\"][target]\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error al consumir API: {e}\")\n",
        "        return None  # fallback seguro"
      ],
      "metadata": {
        "id": "xoniXBMwZYAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/data/loader.py\n",
        "import pandas as pd\n",
        "\n",
        "def load_dataset():\n",
        "    \"\"\"Carga el dataset de German Credit (cl√°sico en ML).\"\"\"\n",
        "    df = pd.read_csv(DATA_URL, sep=r'\\s+', header=None)\n",
        "    # Asignar nombres\n",
        "    df.columns = FEATURE_NAMES + [TARGET_NAME]\n",
        "    return df\n",
        "\n",
        "def load_and_enrich_data():\n",
        "    \"\"\"Carga datos y enriquece con info de API si es relevante.\"\"\"\n",
        "    df = load_dataset()\n",
        "\n",
        "    # Ejemplo: si 'Amount' est√° en EUR, lo convertimos a USD usando API\n",
        "    exchange_rate = fetch_exchange_rate(base=\"EUR\", target=\"USD\")\n",
        "    if exchange_rate:\n",
        "        df[\"Amount_USD\"] = df[\"Amount\"] * exchange_rate\n",
        "        df = df.drop(columns=[\"Amount\"])\n",
        "    else:\n",
        "        df[\"Amount_USD\"] = df[\"Amount\"]  # fallback\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "_rkQGHBGZfVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/data/preprocess.py\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Limpieza, codificaci√≥n y normalizaci√≥n.\"\"\"\n",
        "    # Codificar variables categ√≥ricas\n",
        "    df = df.copy()\n",
        "    label_encoders = {}\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        le = LabelAdapter()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    # Ajustar target: 1 (Good) ‚Üí 1, 2 (Bad) ‚Üí 0\n",
        "    df[\"Credit_risk\"] = df[\"Credit_risk\"].map({1: 1, 2: 0})\n",
        "\n",
        "    X = df.drop(columns=[\"Credit_risk\"])\n",
        "    y = df[\"Credit_risk\"]\n",
        "\n",
        "    # Normalizaci√≥n\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return X_scaled, y.values, scaler\n",
        "\n",
        "def split_data(X, y, test_size=0.2, random_state=42):\n",
        "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
        "\n",
        "class LabelAdapter:\n",
        "    \"\"\"Wrapper simple para LabelEncoder con manejo de nuevos valores.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.le = LabelEncoder()\n",
        "        self.classes_ = None\n",
        "\n",
        "    def fit_transform(self, y):\n",
        "        self.le.fit(y)\n",
        "        self.classes_ = self.le.classes_\n",
        "        return self.le.transform(y)\n",
        "\n",
        "    def transform(self, y):\n",
        "        # Manejar valores desconocidos\n",
        "        y = pd.Categorical(y, categories=self.classes_).fillna(self.classes_[0])\n",
        "        return self.le.transform(y)"
      ],
      "metadata": {
        "id": "gidB5da1aI1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/model/neural_net.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "def build_credit_model(input_dim=INPUT_DIM):\n",
        "    \"\"\"\n",
        "    Modelo profundo para clasificaci√≥n binaria de riesgo crediticio.\n",
        "    Incluye:\n",
        "      - Regularizaci√≥n L2\n",
        "      - Dropout\n",
        "      - Activaciones ReLU\n",
        "      - Salida sigmoide\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(\n",
        "            128,\n",
        "            activation='relu',\n",
        "            input_shape=(input_dim,),\n",
        "            kernel_regularizer=regularizers.l2(1e-4)\n",
        "        ),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(\n",
        "            64,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=regularizers.l2(1e-4)\n",
        "        ),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(\n",
        "            32,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=regularizers.l2(1e-4)\n",
        "        ),\n",
        "        layers.Dense(1, activation='sigmoid')  # Clasificaci√≥n binaria\n",
        "    ])\n",
        "\n",
        "    # Optimizador Adam\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=0.001,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-07\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(name=\"precision\"),\n",
        "            tf.keras.metrics.Recall(name=\"recall\")\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "YhW4I3L5aouq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/model/train.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "def train_credit_model(model, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history"
      ],
      "metadata": {
        "id": "A3DouY0oa0VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/model/predict.py\n",
        "import numpy as np\n",
        "\n",
        "def predict_credit_approval(model, X_sample, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Predice si se aprueba cr√©dito.\n",
        "    Retorna: (probabilidad, decisi√≥n_binaria)\n",
        "    \"\"\"\n",
        "    prob = model.predict(X_sample)\n",
        "    decision = (prob >= threshold).astype(int)\n",
        "    return prob, decision"
      ],
      "metadata": {
        "id": "-kPqh2uxbGTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/visualization/plot_training.py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(history):\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "    metrics = ['loss', 'accuracy', 'precision', 'recall']\n",
        "    for i, metric in enumerate(metrics):\n",
        "        ax = axs[i//2, i%2]\n",
        "        ax.plot(history.history[metric], label='Train')\n",
        "        ax.plot(history.history[f'val_{metric}'], label='Val')\n",
        "        ax.set_title(f'Model {metric}')\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Xl4C8C_6bJCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/visualization/plot_activations.py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_layer_activations(model, input_sample, layer_index=0):\n",
        "    \"\"\"Visualiza activaciones de una capa densa (ej. primera).\"\"\"\n",
        "    if len(input_sample.shape) == 1:\n",
        "        input_sample = np.expand_dims(input_sample, axis=0)\n",
        "\n",
        "    layer_outputs = [layer.output for layer in model.layers]\n",
        "    activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "    activations = activation_model.predict(input_sample)\n",
        "\n",
        "    activation = activations[layer_index]\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.matshow(activation, cmap='viridis', fignum=1)\n",
        "    plt.title(f\"Activaciones - Capa {layer_index} ({model.layers[layer_index].name})\")\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8HfK9f1bbS8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/visualization/plot_architecture.py\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import os\n",
        "\n",
        "def plot_model_architecture(model, to_file='model_architecture.png', show_shapes=True):\n",
        "    plot_model(model, to_file=to_file, show_shapes=show_shapes, show_layer_names=True)\n",
        "    print(f\"Arquitectura guardada en: {os.path.abspath(to_file)}\")"
      ],
      "metadata": {
        "id": "Q11uWZvTbXMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/tests/test_preprocess.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Ensure cell gidB5da1aI1Q (src/data/preprocess.py) is run before this cell.\n",
        "\n",
        "def test_preprocess_output():\n",
        "    df = pd.DataFrame({\n",
        "        \"A\": [\"x\", \"y\", \"x\"],\n",
        "        \"B\": [10, 20, 30],\n",
        "        \"Credit_risk\": [1, 2, 1]\n",
        "    })\n",
        "    X, y, scaler = preprocess_data(df) # preprocess_data will be globally available after gidB5da1aI1Q runs\n",
        "    assert X.shape[1] == 2\n",
        "    assert set(np.unique(y)) == {0, 1}\n"
      ],
      "metadata": {
        "id": "Hm52ySxabpoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/tests/test_api_client.py\n",
        "\n",
        "def test_api_client():\n",
        "    rate = fetch_exchange_rate(\"USD\", \"EUR\")\n",
        "    assert rate is None or (isinstance(rate, float) and rate > 0)"
      ],
      "metadata": {
        "id": "mq4j-0tAbe8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src/main.py\n",
        "# from src.data.loader import load_and_enrich_data\n",
        "# from src.data.preprocess import preprocess_data, split_data\n",
        "# from src.model.neural_net import build_credit_model\n",
        "# from src.model.train import train_credit_model\n",
        "# from src.model.predict import predict_credit_approval\n",
        "# from src.visualization.plot_training import plot_training_history\n",
        "# from src.visualization.plot_architecture import plot_model_architecture\n",
        "# from src.visualization.plot_activations import plot_layer_activations\n",
        "# from src.config import INPUT_DIM\n",
        "\n",
        "def main():\n",
        "    print(\"üöÄ Iniciando sistema de predicci√≥n de cr√©dito...\")\n",
        "\n",
        "    # 1. Cargar y enriquecer datos\n",
        "    df = load_and_enrich_data()\n",
        "    print(f\"Datos cargados: {df.shape}\")\n",
        "\n",
        "    # 2. Preprocesar\n",
        "    X, y, scaler = preprocess_data(df)\n",
        "    X_train, X_val, y_train, y_val = split_data(X, y)\n",
        "\n",
        "    # 3. Construir modelo\n",
        "    model = build_credit_model(input_dim=X.shape[1])\n",
        "    model.summary()  # No usar print()\n",
        "\n",
        "    # 4. Entrenar\n",
        "    history = train_credit_model(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "    # 5. Visualizaciones\n",
        "    plot_training_history(history)\n",
        "    plot_model_architecture(model, \"credit_model.png\")\n",
        "\n",
        "    # 6. Ejemplo de predicci√≥n\n",
        "    sample = X_val[0:1]\n",
        "    prob, decision = predict_credit_approval(model, sample)\n",
        "    print(f\"Probabilidad de aprobaci√≥n: {prob[0][0]:.2%}\")\n",
        "    print(f\"Decisi√≥n: {'APROBADO' if decision[0][0] else 'RECHAZADO'}\")\n",
        "\n",
        "    # 7. Visualizar activaciones internas\n",
        "    plot_layer_activations(model, sample, layer_index=0)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "CBig1nUedLDc",
        "outputId": "e86d2f97-9d51-46ce-da50-d7b4b9ecf8d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando sistema de predicci√≥n de cr√©dito...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length mismatch: Expected axis has 1 elements, new values have 21 elements",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2326051287.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2326051287.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# 1. Cargar y enriquecer datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_enrich_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Datos cargados: {df.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2732073992.py\u001b[0m in \u001b[0;36mload_and_enrich_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_enrich_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\"Carga datos y enriquece con info de API si es relevante.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Ejemplo: si 'Amount' est√° en EUR, lo convertimos a USD usando API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2732073992.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'\\s+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Asignar nombres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFEATURE_NAMES\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTARGET_NAME\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6312\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6314\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6315\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mproperties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m    813\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 21 elements"
          ]
        }
      ]
    }
  ]
}